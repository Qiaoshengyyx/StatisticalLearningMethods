---
permalink: /_posts/chapter4.html
title: chapter4
layout: post
---

# 朴素贝叶斯法

## 简介
基于特征条件独立假设 学习输入输出的联合概率分布，得到朴素贝叶斯模型，对给定的输入，利用贝叶斯定理求出后验概率最大的输出y。

## 朴素贝叶斯模型

### 基本方法
给定数据集$X=\{x_1, x_2, ..., x_K \}$, 标签集合$Y=\{c_1, c_2, ..., c_K\}，共K个样本。$
对于待预测输入$x$，要得到$P(y=c_k|x)$，即给定输入计算每个类别的概率，根据贝叶斯定理，有：
$$
P(Y=c_k|X=x)   = \frac{P(X=x|Y=c_k)P(Y=c_k)}{\sum_{k}P(X=x|Y=c_k)P(Y=c_k)}
$$
在条件独立性假设下，可得：
$$
P(Y=c_k|X=x) = \frac{P(Y=c_k)\prod_{j}P(X^{(j)}=x^{(j)}|Y=c_k)}{\sum_{k}(P(Y=c_k)\prod_{j}P(X^{(j)}=x^{(j)}|Y=c_k))}
$$
结果就是取概率最大的类别为输出：
$$
y=f(x)=\underset {c_k} {\operatorname {arg\,max}}\frac{P(Y=c_k)\prod_{j}P(X^{(j)}=x^{(j)}|Y=c_k)}{\sum_{k}(P(Y=c_k)\prod_{j}P(X^{(j)}=x^{(j)}|Y=c_k))}
$$
因为分母求的是$P(X=x)$，$x$是新的输入，因此它对所有$c_k$都是相同的，输出可以简化为：
$$
y=f(x)=\underset {c_k} {\operatorname {arg\,max}}{P(Y=c_k)\prod_{j}P(X^{(j)}=x^{(j)}|Y=c_k)}   \tag{1}
$$

### 参数估计
根据公式(1)，可知需要估计$P(Y=c_k)$与$P(X^{(j)}=x^{(j)}|Y=c_k)$，用极大似然估计，有：
$$
P(Y=c_k) = \frac{\sum_{i=1}^{N}I(y_i=c_k)}{N}
$$
即每个类别出现的频率， N是样本总数，函数I表示统计出现次数。

第二个是$P(X^{(j)}=x^{(j)}|Y=c_k)$，假设$x$的维度为n,即特征数量为n。每个特征$x^{(j)}$都可能有多种取值，设第j个特征$x^{(j)}$可能取值个数为$S_j$，取值集合为$\{a_{j1}, a_{j2}, ..., a_{jS_j}\}$。

根据$P(A|B)=\frac{P(AB)}{P(B)}$，有：
$$
\begin{aligned}
P(X^{(j)}=a_{jl}|Y=c_k) & = \frac{P(X^{(j)}=a_{jl}, Y=c_k)}{P(Y=c_k)}    \\
& = \frac{\frac{\sum_{i=1}^{N}I(x_{i}^{j}=a_{jl},y_i=c_k)}{N}}{\frac{\sum_{i=1}^{N}I(y_i=c_k)}{N}} \\
& = \frac{\sum_{i=1}^{N}I(x_{i}^{j}=a_{jl},y_i=c_k)}{\sum_{i=1}^{N}I(y_i=c_k)}
\end{aligned}
$$
即计算每个类别中，每个特征的每一种取值的概率，从而也能想到可能会出现 待预测的输入中 某个维度有未出现过的取值，可以预先设定这种情况的概率为固定值。

### 贝叶斯估计
上述参数估计方法可能出现概率值为0的情况，解决方法是采用贝叶斯估计。
$$
P_{\lambda}(X^{(j)}=a_{jl}|Y=c_k)  = \frac{\sum_{i=1}^{N}I(x_{i}^{j}=a_{jl},y_i=c_k)+\lambda }{\sum_{i=1}^{N}I(y_i=c_k)+S_{j}\lambda}
$$
常取$\lambda=1$，此时称为拉普拉斯平滑。

## 习题
**4.1** 用极大似然估计法推出朴素贝叶斯法中的概率估计公式(4.8)及公式 (4.9)

**4.2**

**4.3**