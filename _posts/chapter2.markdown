# 感知机
## 简介
感知机是一个**二分类**的**线性分类模型**，输出取+1和-1二值，属于**判别模型**。

## 感知机模型
设输入x是n维的向量，有函数：
$$
f(x)=sign(w \cdot x+b)
$$
其中：
$$
sign(x)=\left\{
    \begin{aligned}
    +1,& \ \ x\geq 0 \\
    -1,& \ \ x\lt 0 \\
    \end{aligned}
\right.
$$

将$w \cdot x+b=0$理解为一个超平面，用它来分离点。

## 损失函数
点$x_0$到上述超平面的距离为$\frac{1}{||w||}(w\cdot x_0 + b)$ 。
当一个点$x_i$ 被误分类时，设真实类别$\hat y_i$，预测类别$y_i$, 则有：$-y_i(w\cdot x_i + b) > 0$。
该点到超平面的距离为：$-\frac{1}{||w||}y_i(w\cdot x_i + b)$。（这样就拿掉了绝对值）
用**误分类点到超平面到距离总和**作为损失函数，M为误分类点集合，得到的损失函数如下：
$$
L(w,b) = -\sum_{x_i \in M}y_i(w\cdot x_i +b)
$$
上式不考虑$\frac{1}{||w||}$。

## 学习算法
### 感知机算法的原始形式
根据损失函数，目标就是最小化损失函数，使用随机梯度下降法，不断极小化目标函数。其中，极小化过程是**每次随机选取一个误分类点使其梯度下降**。
计算偏导数：
$$
\nabla_wL(w,b)=-\sum_{x_i\in M}y_ix_i \\
\nabla_bL(w,b)=-\sum_{x_i\in M}y_i
$$
则更新$w$和$b$的公式为：
$$
w \leftarrow w+\eta y_ix_i\\
b \leftarrow b+\eta y_i
$$
其中$0 \lt \eta \le 1$

该算法直观上可理解为每遇到一个误分类点，调整w、b的值，使得超平面往误分类点一侧移动，这样距离就变小了。当超平面越过误分类点，该点就被正确分类了。

> 写代码的时候注意到当$w\cdot x+b =0$的时候，$sign(w\cdot x+b)=0$，此时点在超平面上所以也是分类错误的点？

### 学习算法的收敛性证明
当训练集线性可分时，感知机学习算法原始形式迭代是收敛的，且存在多解答，对分离超平面增加约束条件可以得到唯一超平面。

## 感知机算法的对偶形式
